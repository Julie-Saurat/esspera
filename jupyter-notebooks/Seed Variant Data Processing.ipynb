{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import ibm_db\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# if ibm_db still fails on Windows, download https://public.dhe.ibm.com/ibmdl/export/pub/software/data/db2/drivers/odbc_cli/ and extract to the location of ibm_db.py\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize environment variables, connect to DB2, connect WML API client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "db2_connection = ibm_db.connect(os.environ.get('DB2_CONNECTION_STRING'), '', '')\n",
    "\n",
    "wml_credentials = {\n",
    "  'url': os.environ.get('WML_URL'),\n",
    "  'apikey': os.environ.get('WML_API_KEY')\n",
    "}\n",
    "wml_client = APIClient(wml_credentials)\n",
    "wml_client.set.default_project(os.environ.get('WSTUDIO_PROJECT_ID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanup_input_data: Fill dataframe's NaN with 0s.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **data_asset_df**: dataframe: the dataframe to clean up\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return type**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_input_data(data_asset_df):\n",
    "  data_asset_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_weather_avg_for_month: Call TWC API to get weather for particular month, the API returns a list of precipitation and temperature per hour.\n",
    "For the temperature, we take an average sum/size; For precipitation, we simply get a sum.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **row**: dataframe row: a single row from the dataframe\n",
    "2. **from_month**: String: from month inclusive (with the 0 in front if applicable)\n",
    "3. **to_month**: String: to month exclusive (with the 0 in front if applicable)\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return types**: \n",
    "\n",
    "1. **Series**: Series consisting of average temperature in C and total precipitation in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_avg_for_month(row, from_month, to_month):\n",
    "  geocode = row['Coordinates']\n",
    "  year = row['Year']\n",
    "  api_key = os.environ.get('TWC_API_KEY')\n",
    "  weather_request_URL = f'https://api.weather.com/v3/wx/hod/r1/direct?geocode={geocode}&startDateTime={year}-{from_month}-01T00Z&endDateTime={year}-{to_month}-01T00Z&format=json&units=m&apiKey={api_key}'\n",
    "  \"\"\"\n",
    "  {\n",
    "    \"requestedLatitude\": [43.34, ...],\n",
    "    ...\n",
    "    \"precip1Hour\": [0.00, 0.00, ...],\n",
    "    ...\n",
    "    \"temperature\": [56.2, 52.3, ...],\n",
    "    ...\n",
    "  }\n",
    "  \"\"\"\n",
    "  request_result = requests.get(weather_request_URL, timeout=120)\n",
    "  request_result_json = request_result.json()\n",
    "  precipitation_list = request_result_json['precip1Hour']\n",
    "  total_precipitation = sum(precipitation_list)\n",
    "  temperature_list = request_result_json['temperature']\n",
    "  average_temperature = sum(temperature_list) / len(temperature_list)\n",
    "  return pd.Series([average_temperature, total_precipitation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add_weather_data: Call get_weather_avg_for_month for the months of May, June, July, August, September for every row.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **data_asset_df**: dataframe: the dataframe where the temperature and precipitation for May, June, July, August, and September will be added\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return type**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_data(data_asset_df):\n",
    "  # May\n",
    "  data_asset_df[['May Temperature', 'May Precipitation']] = data_asset_df.apply(get_weather_avg_for_month, axis=1, args=(\"05\", \"06\"))\n",
    "  # June\n",
    "  data_asset_df[['June Temperature', 'June Precipitation']] = data_asset_df.apply(get_weather_avg_for_month, axis=1, args=(\"06\", \"07\"))\n",
    "  # July\n",
    "  data_asset_df[['July Temperature', 'July Precipitation']] = data_asset_df.apply(get_weather_avg_for_month, axis=1, args=(\"07\", \"08\"))\n",
    "  # August\n",
    "  data_asset_df[['August Temperature', 'August Precipitation']] = data_asset_df.apply(get_weather_avg_for_month, axis=1, args=(\"08\", \"09\"))\n",
    "  # September\n",
    "  data_asset_df[['September Temperature', 'September Precipitation']] = data_asset_df.apply(get_weather_avg_for_month, axis=1, args=(\"09\", \"10\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_soil_type: Call soilgrids API from ISRIC.org to get the soil type for specific coordinates.\n",
    "We take the one with the highest probability.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **row**: dataframe row: a single row from the dataframe\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return types**: \n",
    "\n",
    "1. **String**: the soil type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soil_type(row):\n",
    "  lat, lng = row['Coordinates'].split(',')\n",
    "  soil_type_request_URL = f'https://rest.isric.org/soilgrids/v2.0/classification/query?lon={lng}&lat={lat}&number_classes=1'\n",
    "  \"\"\"\n",
    "  Example of JSON response:\n",
    "  {\n",
    "    \"type\": \"Point\",\n",
    "    ...\n",
    "    \"wrb_class_name\": \"Phaeozems\",\n",
    "    \"wrb_class_value\": 20,\n",
    "    \"wrb_class_probability\": [[\"Phaeozems\", 40]]\n",
    "  }\n",
    "  \"\"\"\n",
    "  request_result = requests.get(soil_type_request_URL, timeout=120)\n",
    "  soil_type = request_result.json()['wrb_class_name']\n",
    "  return soil_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add_soil_data: Call get_soil_type for every row.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **data_asset_df**: dataframe: the dataframe where the soil type column will be added\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return type**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_soil_data(data_asset_df):\n",
    "  data_asset_df['Soil Type'] = data_asset_df.apply(get_soil_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store_updated_data_asset: Convert the dataframe back to CSV and upload as data asset to Watson Studio.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **data_asset_df**: dataframe: the dataframe to be converted to CSV and stored as data asset\n",
    "2. **data_asset_name**: String: to be used as the new name of the data asset that will be stored in Watson Studio\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return type**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_updated_data_asset(data_asset_df, data_asset_name):\n",
    "  data_asset_df.to_csv(data_asset_name, encoding='utf-8', index=False)\n",
    "  metadata = {\n",
    "    wml_client.data_assets.ConfigurationMetaNames.NAME: data_asset_name,\n",
    "    wml_client.data_assets.ConfigurationMetaNames.DATA_CONTENT_NAME: data_asset_name\n",
    "  }\n",
    "  asset_details = wml_client.data_assets.store(meta_props=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete_data_asset: Delete the data asset from Watson Studio.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **data_asset_uid**: String: data asset uid to be deleted\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return type**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data_asset(data_asset_uid):\n",
    "  wml_client.data_assets.delete(data_asset_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_model: Create a simple linear regression model\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **data_asset_df**: dataframe: dataframe that will be used to fit the linear regression model\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return types**:\n",
    "\n",
    "1. **sklearn/xgboost/spark model**: model with the data fitted\n",
    "2. **array**: list of soil types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_asset_df):\n",
    "  y = data_asset_df['Yield (bu/A)'].values.astype(np.int64)\n",
    "\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "  data_asset_df.drop(['Crop Type'], axis = 1, inplace=True)\n",
    "  data_asset_df.drop(['Brand'], axis = 1, inplace=True)\n",
    "  data_asset_df.drop(['Seed'], axis = 1, inplace=True)\n",
    "  data_asset_df.drop(['Year'], axis = 1, inplace=True)\n",
    "  data_asset_df.drop(['Coordinates'], axis = 1, inplace=True)\n",
    "  data_asset_df.drop(['Yield (bu/A)'], axis = 1, inplace=True)\n",
    "  data_asset_df['Soil Type'] = label_encoder.fit_transform(data_asset_df['Soil Type'])\n",
    "\n",
    "  X = data_asset_df.values.astype(np.float64)\n",
    "\n",
    "  linear_regression_model = LinearRegression()\n",
    "  linear_regression_model.fit(X, y)\n",
    "\n",
    "  return linear_regression_model, label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_model_info_from_db: Get the stored model id and deployment id from the database\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **crop_type**: String: the crop type\n",
    "2. **seed_brand**: String: the seed brand name\n",
    "3. **seed_variant**: String: the seed variant name\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return types**:\n",
    "\n",
    "1. **True/False**: depending if the row exists or not\n",
    "2. **None or String**: if String, it will be the uid of the current WML model\n",
    "3. **None or String**: if String, it will be the uid of the current WML deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info_from_db(crop_type, seed_brand, seed_variant):\n",
    "  sql_stmt = 'select MODEL_ID, DEPLOYMENT_ID from WML_MODELS where CROP_TYPE = ? and SEED_VARIANT_BRAND = ? and SEED_VARIANT_NAME = ?'\n",
    "  prep_stmt = ibm_db.prepare(db2_connection, sql_stmt)\n",
    "  ibm_db.bind_param(prep_stmt, 1, crop_type)\n",
    "  ibm_db.bind_param(prep_stmt, 2, seed_brand)\n",
    "  ibm_db.bind_param(prep_stmt, 3, seed_variant)\n",
    "  ibm_db.execute(prep_stmt)\n",
    "  row = ibm_db.fetch_both(prep_stmt)\n",
    "  if(row):\n",
    "    return True, row['MODEL_ID'], row['DEPLOYMENT_ID']\n",
    "  return False, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_or_update_model: Create/Update model and create a new revision\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **crop_type**: String: the crop type\n",
    "2. **seed_brand**: String: the seed brand name\n",
    "3. **seed_variant**: String: the seed variant name\n",
    "4. **trained_model**: sklearn/xgboost/spark model: the model that was trained with the data\n",
    "5. **model_id**: None/String: WML uid of an existing model to update\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return types**:\n",
    "\n",
    "1. **String**: uid of the WML model\n",
    "2. **int**: the revision number of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_model(crop_type, seed_brand, seed_variant, trained_model, model_id):\n",
    "  wml_client.set.default_space(os.environ.get('WSTUDIO_SPACE_ID'))\n",
    "  if(model_id is not None):\n",
    "    wml_client.repository.update_model(existing_model_id, updated_meta_props=None, update_model=trained_model)\n",
    "  else:\n",
    "    sofware_spec_uid = wml_client.software_specifications.get_id_by_name('runtime-22.1-py3.9')\n",
    "    model_metadata = {\n",
    "      wml_client.repository.ModelMetaNames.NAME: f'Model for {crop_type} - {seed_brand} - {seed_variant}',\n",
    "      wml_client.repository.ModelMetaNames.TYPE: 'scikit-learn_1.0',\n",
    "      wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid,\n",
    "      wml_client.repository.ModelMetaNames.INPUT_DATA_SCHEMA: { \n",
    "        'id': 'model_input_schema',\n",
    "        'fields': [\n",
    "          {'name': 'May Temperature', 'type': 'double'},\n",
    "          {'name': 'May Precipitation', 'type': 'double'},\n",
    "          {'name': 'June Temperature', 'type': 'double'},\n",
    "          {'name': 'June Precipitation', 'type': 'double'},\n",
    "          {'name': 'July Temperature', 'type': 'double'},\n",
    "          {'name': 'July Precipitation', 'type': 'double'},\n",
    "          {'name': 'August Temperature', 'type': 'double'},\n",
    "          {'name': 'August Precipitation', 'type': 'double'},\n",
    "          {'name': 'September Temperature', 'type': 'double'},\n",
    "          {'name': 'September Precipitation', 'type': 'double'},\n",
    "          {'name': 'Soil Type', 'type': 'int'}\n",
    "        ]\n",
    "      },\n",
    "      wml_client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA: { \n",
    "        'id': 'model_output_schema',\n",
    "        'fields': [\n",
    "          {\n",
    "            'name': 'Yield (bu/A)',\n",
    "            'type': 'int',\n",
    "            'metadata': {\n",
    "              'modeling_role': 'prediction'\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "    stored_model = wml_client.repository.store_model(model=trained_model, meta_props=model_metadata)\n",
    "    model_id = wml_client.repository.get_model_id(stored_model)\n",
    "\n",
    "  created_model_revision = wml_client.model_definitions.create_revision(model_id)\n",
    "  \"\"\"\n",
    "  Example JSON for model_definition_revision:\n",
    "  {\n",
    "    'metadata': {\n",
    "      ...\n",
    "      'asset_type': 'wml_model',\n",
    "      'created_at': '2022-10-26T06:57:50Z',\n",
    "      'last_updated_at': '2022-10-26T07:02:05Z',\n",
    "      'revision_id': 3,\n",
    "      'name': 'Model for Testing',\n",
    "      ...\n",
    "    }\n",
    "  }\n",
    "  \"\"\"\n",
    "  model_revision_id = created_model_revision['metadata']['revision_id']\n",
    "\n",
    "  return model_id, model_revision_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_or_update_deployment: Create/Update the online deployment\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **crop_type**: String: the crop type\n",
    "2. **seed_brand**: String: the seed brand name\n",
    "3. **seed_variant**: String: the seed variant name\n",
    "4. **model_id**: String: WML uid of the model to deploy\n",
    "5. **model_revision_id**: int: WML uid of the revision of the model\n",
    "6. **deployment_id**: None/String: WML uid of an existing deployment to update\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return types**:\n",
    "\n",
    "1. **String**: uid of the WML deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_deployment(crop_type, seed_brand, seed_variant, model_id, model_revision_id, deployment_id):\n",
    "  wml_client.set.default_space(os.environ.get('WSTUDIO_SPACE_ID'))\n",
    "  if(deployment_id is not None):\n",
    "    deployment_metadata = {\n",
    "      client.deployments.ConfigurationMetaNames.ASSET: {\n",
    "        'id': model_id,\n",
    "        'rev': model_revision_id\n",
    "      }\n",
    "    }\n",
    "    updated_deployment = client.deployments.update(deployment_id, changes=deployment_metadata)\n",
    "  else:\n",
    "    deployment_metadata = {\n",
    "      wml_client.deployments.ConfigurationMetaNames.NAME: f'Deployment for {crop_type} - {seed_brand} - {seed_variant}',\n",
    "      wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    "    created_deployment = wml_client.deployments.create(model_id, meta_props=deployment_metadata, rev_id=str(model_revision_id))\n",
    "    deployment_id = wml_client.deployments.get_id(created_deployment)\n",
    "\n",
    "  return deployment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update_model_info_in_db: Upsert the model id and deployment id in the database\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **info_exists_in_db**: True/False: depending it the entry exists in the database or not\n",
    "2. **crop_type**: String: the crop type\n",
    "3. **seed_brand**: String: the seed brand name\n",
    "4. **seed_variant**: String: the seed variant name\n",
    "5. **model_id**: String: WML uid of the model\n",
    "6. **deployment_id**: String: WML uid of the deployment\n",
    "7. **soil_type_list**: String: list of soil types separated by comma\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return type**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_info_in_db(info_exists_in_db, crop_type, seed_brand, seed_variant, model_id, deployment_id, soil_type_list):\n",
    "  soil_types = ','.join(str(x) for x in soil_type_list)\n",
    "  \n",
    "  if(info_exists_in_db):\n",
    "    sql_stmt = 'update WML_MODELS set MODEL_ID = ?, DEPLOYMENT_ID = ?, MODEL_SOIL_TYPES = ?, MODDATE = current timestamp where CROP_TYPE = ? and SEED_VARIANT_BRAND = ? and SEED_VARIANT_NAME = ?'\n",
    "    prep_stmt = ibm_db.prepare(db2_connection, sql_stmt)\n",
    "    ibm_db.bind_param(prep_stmt, 1, model_id)\n",
    "    ibm_db.bind_param(prep_stmt, 2, deployment_id)\n",
    "    ibm_db.bind_param(prep_stmt, 3, soil_types)\n",
    "    ibm_db.bind_param(prep_stmt, 4, crop_type)\n",
    "    ibm_db.bind_param(prep_stmt, 5, seed_brand)\n",
    "    ibm_db.bind_param(prep_stmt, 6, seed_variant)\n",
    "    ibm_db.execute(prep_stmt)\n",
    "  else:\n",
    "    sql_stmt = 'insert into WML_MODELS (MODEL_ID, DEPLOYMENT_ID, MODEL_SOIL_TYPES, CROP_TYPE, SEED_VARIANT_BRAND, SEED_VARIANT_NAME, MODDATE) values (?, ?, ?, ?, ?, ?, current timestamp)'\n",
    "    prep_stmt = ibm_db.prepare(db2_connection, sql_stmt)\n",
    "    ibm_db.bind_param(prep_stmt, 1, model_id)\n",
    "    ibm_db.bind_param(prep_stmt, 2, deployment_id)\n",
    "    ibm_db.bind_param(prep_stmt, 3, soil_types)\n",
    "    ibm_db.bind_param(prep_stmt, 4, crop_type)\n",
    "    ibm_db.bind_param(prep_stmt, 5, seed_brand)\n",
    "    ibm_db.bind_param(prep_stmt, 6, seed_variant)\n",
    "    ibm_db.execute(prep_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process_new_csv: Get the content of the data asset and convert to a dataframe. Do some cleanup, add the weather data, add the soil type, then upload the complete CSV to Watson Studio, and delete the original CSV so we do not process it again.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **data_asset_uid**: String: the uid of the data asset to get the content from\n",
    "2. **data_asset_name**: String: the name of the data asset\n",
    "\n",
    "**Output**\n",
    "\n",
    "**Return type**: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_csv(data_asset_uid, data_asset_name):\n",
    "  data_asset_content = wml_client.data_assets.get_content(data_asset_uid)\n",
    "  data_asset_content_str = data_asset_content.decode('utf-8')\n",
    "  data_asset_df = pd.read_table(StringIO(data_asset_content_str), sep=',')\n",
    "\n",
    "  crop_type = data_asset_df['Crop Type'].iloc[0]\n",
    "  seed_brand = data_asset_df['Brand'].iloc[0]\n",
    "  seed_variant = data_asset_df['Seed'].iloc[0]\n",
    "\n",
    "  cleanup_input_data(data_asset_df)\n",
    "  add_weather_data(data_asset_df)\n",
    "  add_soil_data(data_asset_df)\n",
    "  store_updated_data_asset(data_asset_df, data_asset_name.removeprefix('New'))\n",
    "  delete_data_asset(data_asset_uid)\n",
    "\n",
    "  model, soil_type_list = train_model(data_asset_df)\n",
    "\n",
    "  info_exists_in_db, existing_model_id, existing_deployment_id = get_model_info_from_db(crop_type, seed_brand, seed_variant)\n",
    "  model_id, model_revision_id = create_or_update_model(crop_type, seed_brand, seed_variant, model, existing_model_id)\n",
    "  deployment_id = create_or_update_deployment(crop_type, seed_brand, seed_variant, model_id, model_revision_id, existing_deployment_id)\n",
    "  update_model_info_in_db(info_exists_in_db, crop_type, seed_brand, seed_variant, model_id, deployment_id, soil_type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through data assets and process the CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we get list of data assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------  ----------  ----  ------------------------------------\n",
      "NAME                             ASSET_TYPE  SIZE  ASSET_ID\n",
      "SeedData_Corn_C478DP.csv         data_asset  3335  1170c1a8-8bfb-4559-9159-f589fd2e05ea\n",
      "NewSeedData_Corn_T6791 VT2P.csv  data_asset  899   66d85d02-a02a-4b9d-977f-536f8be243d2\n",
      "-------------------------------  ----------  ----  ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_assets_details = wml_client.data_assets.get_details()\n",
    "wml_client.data_assets.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we loop to see which one starts with NewSeedData_ and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data asset...\n",
      "SUCCESS\n",
      "Unsetting the project_id ...\n",
      "Creating model_definition revision...\n",
      "DONE\n",
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '67a02bc2-bb53-46a1-9eeb-f03c208ffa4d' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "initializing\n",
      "Note: online_url is deprecated and will be removed in a future release. Use serving_urls instead.\n",
      "\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='bf26766e-120c-46e7-abfb-a8b7aa48b17a'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example of JSON for data_assets_details\n",
    "{\n",
    "  \"resources\":[\n",
    "    {\n",
    "      \"metadata\":{\n",
    "        \"project_id\":\"b2843657-348d-43e9-89ce-204399a0e0bc\",\n",
    "        ...\n",
    "        \"name\":\"SeedVariantData_Early Maturity Corn - DS-4014Q.csv\",\n",
    "        \"asset_type\":\"data_asset\",\n",
    "        ...\n",
    "        \"resource_key\":\"SeedVariantData_Early Maturity Corn - DS-4014Q.csv\",\n",
    "        ...\n",
    "        \"asset_id\":\"af25dcd9-86f5-401e-b178-51e332e9f684\",\n",
    "        ...\n",
    "        \"guid\":\"af25dcd9-86f5-401e-b178-51e332e9f684\",\n",
    "        \"href\":\"/v2/assets/af25dcd9-86f5-401e-b178-51e332e9f684?project_id=b2843657-348d-43e9-89ce-204399a0e0bc\",\n",
    "        \"last_updated_at\":\"2022-10-23T07:55:35Z\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "data_asset_metadata_list = data_assets_details['resources']\n",
    "for data_asset_metadata_obj in data_asset_metadata_list:\n",
    "  data_asset_metadata = data_asset_metadata_obj['metadata']\n",
    "  data_asset_name = data_asset_metadata['name']\n",
    "  # only processing data assets CSVs where the name starts with NewSeedData_\n",
    "  if(data_asset_name.startswith('NewSeedData_') and data_asset_name.endswith('.csv')):\n",
    "    process_new_csv(data_asset_metadata['asset_id'], data_asset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibm_db.close(db2_connection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "09f84cc61a46f88ef77defbe964397fbc5af45cc6c7f4a71f32b24fab97455a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
